---
description: In diesem Block geht es um wichtige grundlegende Fragen zu Big Data.
---

# \#1 Big Data Grundlagen

## ğŸ¯ Lernziele

* ğŸ¯ Ihr kÃ¶nnt Big Data von herkÃ¶mmlichen Daten anhand wichtiger Charakteristika abgrenzen.
* ğŸ¯ Ihr kennt die Herausforderungen die Big Data mit sich bringt.
* ğŸ¯ Ihr kennt die wichtigsten LÃ¶sungsansÃ¤tze fÃ¼r diese Herausforderungen.

## â“ Fragen

* â“Was charakterisiert Big Data?
* â“Vor welche Herausforderungen stellt uns Big Data?
* â“Warum funktionieren traditionelle LÃ¶sungsansÃ¤tze mit Big Data nicht?
* â“Welche LÃ¶sungsansÃ¤tze gibt es, um diesen Herausforderungen zu begegnen?

## ğŸ· Begriffe

* ğŸ· Die 3 Vs
  * ğŸ·Volume
  * ğŸ·Variety
  * ğŸ·Velocity
* ğŸ·Polystrukturierte Daten 
* ğŸ·Distributed Filesystem and Processing
* ğŸ·Cluster
* ğŸ·HDFS
* â€‹ ğŸ·MapReduce
  * â€‹â€‹ ğŸ·Data Node
  * â€‹â€‹ ğŸ·Worker Node
  * â€‹â€‹ ğŸ·Name Node 
* ğŸ·Apache Spark
  * ğŸ· RDD
  * ğŸ· Spark Transformations und Actions

## ğŸ”‘ Key Points

* ğŸ”‘ Eine verbreitete Option, Big Data zu klassifizieren, ist die Orientierung an den **3 Vs**:
  * Volume = Datenmenge
  * Variety = Datenvielfalt
  * Velocity = Frequenz der Daten\(-erzeugung\) 
* ğŸ”‘ Die 3 Vs stellen uns vor neue Herausforderungen:
  * **Volume**: Einzelne Rechner kÃ¶nnen groÃŸe Datenmengen im Terabytebereich oder grÃ¶ÃŸer nicht mehr speichern oder in angemessener Zeit analysieren.
  * **Variety**: Traditionelle relationale Datenbanken oder Spreadsheets eignen sich nicht fÃ¼r polystrukturierte Daten wie Texte, Bilder oder Dokumente, weil diese entweder keine inhÃ¤rente Struktur haben \(Texte, Bilder\) und/oder weil sie keinem starren Schema in Sinne von Spalten und Werten folgen.
  * **Velocity**: Daten werden oft in schneller Frequenz erzeugt, z.B. Sensordaten oder Social Media Daten. In vielen Szenarien ist die zeitnahe Analyse der Daten zwingend notwendig, man spricht dann auch von _real-time_ oder _near real-time_. Die schnelle Verarbeitung und Analyse von groÃŸen Datenmengen stellt einzelne Rechner und traditionelle Datenbanken \(z. B. relationale Datenbank\) vor Probleme. 
* ğŸ”‘ Ein LÃ¶sungsansatz fÃ¼r das Speichern groÃŸer Datenmengen ist das Verteilen der Daten auf einen _Verbund_ von Rechnern \(ğŸ·Cluster\), statt auf nur einem Rechner. Man spricht dann von einem verteilten Dateisystem \(ğŸ·Distributed Filesystem\). Ein weit verbreitetes System ist das ğŸ·HDFS \(Hadoop Distributed Filesystem\), das groÃŸe Dateien in kleinere BlÃ¶cke aufteilt, die dann mehrfach redundant auf mind. 3 Knoten im ğŸ·Cluster abgelegt werden. 
* ğŸ”‘ Die Verteilung der Arbeitslast auf mehrere Knoten \(_nodes_\) ist auch der wichtigste Ansatz bei der Verarbeitung von Big Data. Dabei wird das Problem oder die Abfrage in parallel verarbeitbare Teilprobleme zerlegt und auf die verfÃ¼gbaren Knoten verteilt. Jedes Teilergebnis wird eingesammelt und zu dem Gesamtergebnis aggregiert. Bekannte Verfahren fÃ¼r das verteile Verarbeiten von Daten \( ğŸ·Distributed Processing\) sind das von Google entwickelte ğŸ·MapReduce oder ğŸ·Apache Spark.  
* âš  Nicht alle Probleme lassen sich in unabhÃ¤ngig voneinander lÃ¶sbare Teilprobleme zerlegen!

