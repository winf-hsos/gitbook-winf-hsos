---
description: In dieser Session lernen wir Hadoop kennen.
---

# Hadoop

## â“ Fragen

* Wie funktioniert verteiltes Verarbeiten \(_distributed processing_\) mit Apache Spark?
* Welche Arten von Datenverarbeitung unterstÃ¼tzt Apache Spark?
* Welche Vorteile bietet ğŸ·Spark gegenÃ¼ber ğŸ·MapReduce?

## ğŸ”‘ Key Points

ğŸ”‘ Wenn wir eine Datei im ğŸ·HDFS speichern wird sie zunÃ¤chst in BlÃ¶cke gleicher GrÃ¶ÃŸe \(im Standard 128 MB\) zerlegt und jeder Block anschlieÃŸend auf mindestens 3 Rechner \(_nodes_\) verteilt. Durch die redundante Speicherung jedes Blocks wird eine hohe Ausfallsicherheit gewÃ¤hrleistet. Sollte ein Knoten ausfallen existieren noch 2 weitere Kopien.

ğŸ”‘ Wenn eine Datei aus dem ğŸ·HDFS abgerufen wird, fragt zunÃ¤chst der _Name Node_ die notwendigen BlÃ¶cke bei den entsprechenden Rechner, auf denen sie gespeichert wurden, an. AnschlieÃŸend werden die BlÃ¶cke in der richtigen Reihenfolge zur angefragten Datei zusammen gefÃ¼gt und zurÃ¼ck geliefert.

ğŸ”‘ Von AuÃŸen betrachtet sieht das ğŸ·HDFS wie ein gewÃ¶hnliches Verzeichnissystem aus, wie man es z.B. aus dem Windows-Explorer gewohnt ist. Auch das Verhalten ist gleich. Die KomplexitÃ¤t, die im Hintergrund fÃ¼r die hohe Performanz und die Ausfallsicherheit sorgt, wird vor dem Benutzer versteckt.

## â–¶ Session

### 1âƒ£ HDFS

### 2âƒ£ MapReduce

